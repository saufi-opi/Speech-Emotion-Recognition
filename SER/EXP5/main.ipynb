{"cells":[{"cell_type":"markdown","metadata":{"id":"vKAQNkfCVKer"},"source":["# **Conv2D-MFCC**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dhb8jjH3cDcb"},"outputs":[],"source":["import numpy as np\n","import librosa\n","import pandas as pd\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21943,"status":"ok","timestamp":1674025114517,"user":{"displayName":"Saufi","userId":"07073297738616340894"},"user_tz":-480},"id":"ectFkHIRcWgD","outputId":"1514e2f7-df04-458e-c640-f73c0a4f8cdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhqtGCL4cDch"},"outputs":[],"source":["data_path=pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/FYP-SER/data_path.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VSAWUCMacDci"},"outputs":[],"source":["def extract_features(data):\n","    data=data[:44100]\n","    zero_padding=tf.zeros([44100] - tf.shape(data), dtype=tf.float32)\n","    data=tf.concat([zero_padding, data], 0)\n","    data=np.array(data)\n","    mfcc=librosa.feature.mfcc(y=data, n_mfcc=50).T\n","    return mfcc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wNq6pssyk5HD"},"outputs":[],"source":["#Data Augmentation\n","\n","def noise(data):\n","    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n","    data = data + noise_amp*np.random.normal(size=data.shape[0])\n","    return data\n","\n","def stretch(data, rate=0.8):\n","    return librosa.effects.time_stretch(data, rate)\n","\n","def pitch(data, sampling_rate, pitch_factor=0.7):\n","    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1nLs43Jsk9Vt"},"outputs":[],"source":["def remove_silent(data):\n","    data=librosa.effects.trim(data, top_db = 30)[0]\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TaSIlx2XcDcj"},"outputs":[],"source":["def get_features(path,i):\n","    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n","    data, sample_rate = librosa.load(path, sr=22050)\n","    data=remove_silent(data)\n","    \n","    # without augmentation\n","    if i==0:\n","      res1 = extract_features(data)\n","      result = np.array(res1)\n","      \n","    # data with noise\n","    if i==1:\n","      noise_data = noise(data)\n","      result = extract_features(noise_data)\n","      # result = np.vstack((result, res2)) # stacking vertically\n","    \n","    # data with stretching and pitching\n","    if i==2:\n","      new_data = stretch(data)\n","      data_stretch_pitch = pitch(new_data, sample_rate)\n","      result = extract_features(data_stretch_pitch)\n","      # result = np.vstack((result, res3)) # stacking vertically\n","    \n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qLufzSqblD2q"},"outputs":[],"source":["X, Y = [], []\n","for path, emotion in zip(data_path.Path, data_path.Emotions):\n","    for i in range(3):\n","        feature = get_features(path,i)\n","        X.append(feature)\n","        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n","        Y.append(emotion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1674026612268,"user":{"displayName":"Saufi","userId":"07073297738616340894"},"user_tz":-480},"id":"fTMpqqOAcDcj","outputId":"efee11fb-1c1b-48f8-d2ee-962a5e934c7d"},"outputs":[{"data":{"text/plain":["(4320, 4320)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["len(X),len(Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9i3FL5Wxfzm6"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Conv1D, MaxPooling1D,MaxPooling2D, Flatten, Dropout, BatchNormalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sp0PzSbnf0Lt"},"outputs":[],"source":["# As this is a multiclass classification problem onehotencoding our Y.\n","encoder = OneHotEncoder()\n","Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"05f_Q56NOJQ4"},"outputs":[],"source":["X=np.array(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1674026612859,"user":{"displayName":"Saufi","userId":"07073297738616340894"},"user_tz":-480},"id":"jddwyjmKf4pi","outputId":"ed0c0425-dd0c-46e7-f616-53a03bfb15b4"},"outputs":[{"data":{"text/plain":["((3240, 87, 50), (3240, 8), (1080, 87, 50), (1080, 8))"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# splitting data\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1674026612860,"user":{"displayName":"Saufi","userId":"07073297738616340894"},"user_tz":-480},"id":"JpjHdafyMhW8","outputId":"986be305-a8e9-4ff5-e6bb-620ec9fc79d4"},"outputs":[{"data":{"text/plain":["((3240, 87, 50, 1), (3240, 8), (1080, 87, 50, 1), (1080, 8))"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# making our data compatible to model.\n","x_train = np.expand_dims(x_train, axis=3)\n","x_test = np.expand_dims(x_test, axis=3)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":401,"status":"ok","timestamp":1674026613241,"user":{"displayName":"Saufi","userId":"07073297738616340894"},"user_tz":-480},"id":"Sqm_Kb8sf6QS","outputId":"015c627c-dbb7-4029-f075-f04987a979b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 87, 50, 256)       6656      \n","                                                                 \n"," batch_normalization (BatchN  (None, 87, 50, 256)      1024      \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 29, 17, 256)      0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 29, 17, 512)       3277312   \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 29, 17, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 10, 6, 512)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 10, 6, 256)        3277056   \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 10, 6, 256)       1024      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 4, 2, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 4, 2, 128)         819328    \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 4, 2, 128)        512       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 2, 1, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                16448     \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 64)               256       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_1 (Dense)             (None, 8)                 520       \n","                                                                 \n","=================================================================\n","Total params: 7,402,184\n","Trainable params: 7,399,752\n","Non-trainable params: 2,432\n","_________________________________________________________________\n"]}],"source":["#Modelling\n","\n","model=Sequential()\n","model.add(Conv2D(256, (5,5), activation='tanh',padding='same', input_shape=(x_train.shape[1],x_train.shape[2],1)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3,3), padding='same'))\n","\n","\n","model.add(Conv2D(512, (5,5), activation='tanh',padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3,3), padding='same'))\n","\n","\n","model.add(Conv2D(256, (5,5), activation='tanh',padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3,3), padding='same'))\n","\n","\n","model.add(Conv2D(128, (5,5), activation='tanh',padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3,3), padding='same'))\n","\n","\n","model.add(Flatten())\n","\n","model.add(Dense(64, activation='tanh'))\n","model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","\n","model.add(Dense(8, activation='softmax'))\n","model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"HKD0UeJtgCDr","outputId":"abbc9062-addb-47ce-b945-e82a6d31ac7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","51/51 [==============================] - 807s 16s/step - loss: 2.1154 - accuracy: 0.2747 - val_loss: 2.3092 - val_accuracy: 0.1778 - lr: 0.0010\n","Epoch 2/100\n","51/51 [==============================] - 799s 16s/step - loss: 1.7274 - accuracy: 0.3812 - val_loss: 2.3229 - val_accuracy: 0.1407 - lr: 0.0010\n","Epoch 3/100\n","51/51 [==============================] - 797s 16s/step - loss: 1.5278 - accuracy: 0.4503 - val_loss: 2.5946 - val_accuracy: 0.2000 - lr: 0.0010\n","Epoch 4/100\n","51/51 [==============================] - 794s 16s/step - loss: 1.4168 - accuracy: 0.4858 - val_loss: 2.7385 - val_accuracy: 0.1426 - lr: 0.0010\n","Epoch 5/100\n","51/51 [==============================] - 795s 16s/step - loss: 1.3811 - accuracy: 0.4901 - val_loss: 2.0639 - val_accuracy: 0.2546 - lr: 0.0010\n","Epoch 6/100\n","51/51 [==============================] - 791s 16s/step - loss: 1.2576 - accuracy: 0.5389 - val_loss: 1.9695 - val_accuracy: 0.3222 - lr: 0.0010\n","Epoch 7/100\n","51/51 [==============================] - 793s 16s/step - loss: 1.1971 - accuracy: 0.5651 - val_loss: 1.6927 - val_accuracy: 0.4380 - lr: 0.0010\n","Epoch 8/100\n","49/51 [===========================>..] - ETA: 28s - loss: 1.1331 - accuracy: 0.5912"]}],"source":["rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n","n_epochs=100\n","history=model.fit(x_train, y_train, batch_size=64, epochs=n_epochs, validation_data=(x_test, y_test), callbacks=[rlrp])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9L_B-peXg8mY"},"outputs":[],"source":["print(\"Accuracy of our model on test data : \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")\n","\n","epochs = [i for i in range(n_epochs)]\n","fig , ax = plt.subplots(1,2)\n","train_acc = history.history['accuracy']\n","train_loss = history.history['loss']\n","test_acc = history.history['val_accuracy']\n","test_loss = history.history['val_loss']\n","\n","fig.set_size_inches(20,6)\n","ax[0].plot(epochs , train_loss , label = 'Training Loss')\n","ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n","ax[0].set_title('Training & Testing Loss')\n","ax[0].legend()\n","ax[0].set_xlabel(\"Epochs\")\n","\n","ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n","ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n","ax[1].set_title('Training & Testing Accuracy')\n","ax[1].legend()\n","ax[1].set_xlabel(\"Epochs\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sa57MjpbhAgI"},"outputs":[],"source":["# predicting on test data.\n","pred_test = model.predict(x_test)\n","y_pred = encoder.inverse_transform(pred_test)\n","\n","y_test = encoder.inverse_transform(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIVtaCjthBJp"},"outputs":[],"source":["df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n","df['Predicted Labels'] = y_pred.flatten()\n","df['Actual Labels'] = y_test.flatten()\n","\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4oX-kLiehD8i"},"outputs":[],"source":["cm = confusion_matrix(y_test, y_pred)\n","plt.figure(figsize = (12, 10))\n","cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n","sns.heatmap(cm, linecolor='white', cmap='Greys', linewidth=1, annot=True, fmt='')\n","plt.title('Confusion Matrix', size=20)\n","plt.xlabel('Predicted Labels', size=14)\n","plt.ylabel('Actual Labels', size=14)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ad3J0sGJhGkO"},"outputs":[],"source":["print(classification_report(y_test, y_pred))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"9ad99cbe8e2c352fa91a16b6cd9fd758e09403de85a2c842709d1818155c9526"}}},"nbformat":4,"nbformat_minor":0}